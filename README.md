# ğŸ“„ Document QA Bot (RAG Project)

## ğŸ“Œ Overview
This is my first Machine Learning / GenAI project ğŸš€  
I built a simple Question-Answering (QA) bot using **Retrieval-Augmented Generation (RAG)**.  

The bot can read a document, store it in a vector database, and then answer natural language questions based only on that document.  

---

## âš™ï¸ How It Works
1. **Document Loading** â€“ Upload a text/PDF file.  
2. **Chunking** â€“ Split the document into smaller parts.  
3. **Embedding** â€“ Convert each chunk into numerical vectors.  
4. **Store in FAISS** â€“ Save embeddings in a vector database for fast retrieval.  
5. **QA Pipeline** â€“ Retrieve relevant chunks + use an LLM to generate answers.  

---

## ğŸ› ï¸ Tech Stack
- Python  
- LangChain  
- FAISS (vector database)  
- Google Colab (runtime environment)  

---

## ğŸš€ Features
- Upload your own document ğŸ“‘  
- Ask natural questions â“  
- Get context-aware answers ğŸ’¡  
- Handles edge cases (like irrelevant/funny questions) gracefully ğŸ¤–  

---

## ğŸ“ Example Interaction
Ask a question (or 'exit'): give three important points from document
Answer: Exploratory analysis, handling missing data, and standardizing formats.

Ask a question (or 'exit'): are you mad?
Answer: No, I'm not mad.

Ask a question (or 'exit'): exit
Thanks for using my QA bot! Bye ğŸ‘‹

---

## ğŸ“‚ Project Files
â”œâ”€â”€ document_qa.ipynb # Main Google Colab notebook

â”œâ”€â”€ README.md # Project documentation

---

## âœ¨ Learning Outcomes
- Understood the basics of the RAG pipeline  
- Hands-on practice with LangChain and FAISS  
- Built a small document-based QA bot  
- Learned how to test for edge cases (irrelevant queries, exit command, casual questions)  

---

## ğŸ”® Future Improvements
- Add support for multiple documents  
- Improve user interface (web/app)  
- Use a more advanced LLM for better answers  

---

This was my **first step into ML/GenAI projects** ğŸ‰  
